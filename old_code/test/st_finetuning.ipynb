{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c904665b-f36e-4f46-837d-26c4a749aaa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 모델 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d9555-0f4d-4208-9af6-2bbbf1b469ef",
   "metadata": {},
   "source": [
    "## sbert모델을 ONNX모델로 export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4b3c0f-2094-4e93-825e-ff216214db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import transformers\n",
    "from transformers.convert_graph_to_onnx import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e8915b-5a14-4ab3-a62d-26647bebd58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 11\n",
      "Loading pipeline (model: jhgan/ko-sroberta-multitask, tokenizer: jhgan/ko-sroberta-multitask)\n",
      "Creating folder model\\onnx\n",
      "Using framework PyTorch: 1.13.1+cpu\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    }
   ],
   "source": [
    "convert(framework=\"pt\", model=\"jhgan/ko-sroberta-multitask\", output=Path(\"./model/onnx/ko-sroberta-multitask.onnx\"), opset=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff52e7-1cb8-4a3f-8aa2-e176622e5efa",
   "metadata": {},
   "source": [
    "## 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96edfb0-7f8b-42b3-99bd-701b45e9aab0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.14.0-cp38-cp38-win_amd64.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 21.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\user\\anaconda3\\envs\\sesac\\lib\\site-packages (from onnxruntime) (1.23.5)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from onnxruntime) (1.12)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\envs\\sesac\\lib\\site-packages (from onnxruntime) (3.19.6)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\sesac\\lib\\site-packages (from onnxruntime) (22.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "     -------------------------------------- 532.6/532.6 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Installing collected packages: pyreadline3, mpmath, sympy, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 mpmath-1.2.1 onnxruntime-1.14.0 pyreadline3-3.4.1 sympy-1.11.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba81650-ef80-4bcb-9e7b-17d4c6310ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a08be0ae-f8b3-4e2c-a3fb-dbaa0f28788f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "quantize_dynamic(\"./model/onnx/ko-sroberta-multitask.onnx\", \"./model/onnx/ko-sroberta-multitask_uint8.onnx\", weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a45d3-111f-46b7-a11b-f742376ce313",
   "metadata": {},
   "source": [
    "# 모델3 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f15ebf3-9b81-4032-8da8-debcdbd58ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc88d9a-488f-4ed4-a069-adcf86e8b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "embedder_onnx = InferenceSession(\"./model/onnx/ko-sroberta-multitask.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "embedder_onnx_uint8 = InferenceSession(\"./model/onnx/ko-sroberta-multitask_uint8.onnx\", providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9dba64-011a-41b7-b327-f50366ca22a7",
   "metadata": {},
   "source": [
    "## 풀링함수\n",
    "SentenceTransformer모델을 자동으로 풀링을 해서 임베딩  \n",
    "ONNX모델은 BERT와 비슷하므로 둘의 임베딩 값을 맞추려면 ONNX모델 결과의 풀링을 거처야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44449543-4576-4f7a-a315-64ba2c5eddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    # model_output의 첫번째 요소는 모든 token의 embedding을 포함\n",
    "    token_embeddings = model_output\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask, input_mask_expanded, sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d87de3-f5dd-43b3-a79f-61b6d919dd0b",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70e1144-256d-4952-bf2f-7bda0de22891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ebcfc2-538f-4dc8-9dd9-74d0a7aaeaf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "files = sorted(glob('./data/*.csv'))\n",
    "data_fit = pd.DataFrame()\n",
    "for file in tqdm(files[:1]):\n",
    "    df_day = pd.read_csv(file, usecols=[\"okt\"])\n",
    "    data_fit = pd.concat([data_fit, df_day])\n",
    "data_fit.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a262a62-8ae5-4ca7-ac3b-4b01368fd78a",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8befb86-8350-481b-835f-3c66e9a210f4",
   "metadata": {},
   "source": [
    "## 기초모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "94734ca8-19e5-43af-b7c6-9728fa45b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f929f9c258b04d0ebf9ed92a311b8c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 21s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = embedder.encode(data_fit.iloc[:,0], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "03aa7a80-edc3-4ce3-962e-528b26a0ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36a116da3e046798ae2f0dc9a2e653b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 30s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings2 = embedder.encode(data_fit.iloc[:,0], show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "86efb423-d990-4a01-bb12-e37d51d93028",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_content = \"\"\"2011년 한국을 떠나 러시아로 귀화한 전 쇼트트랙 선수 빅토르 안(38·한국명 안현수)의 국내 복귀 시도가 일단 무산됐다. 경기도 성남시청 직장운동부 빙상팀 코치에 지원했으나, 최종 후보에 들지 못해서다.\n",
    "\n",
    "성남시는 29일 “시청 빙상팀 코치직 채용 전형에 빅토르 안을 포함해 7명이 지원했는데, 빅토르 안은 상위 2배수 후보에 들지 않았다”고 밝혔다. 시 관계자는 “서류와 면접 심사를 통해 기술, 소통 능력 등 여러 요소를 종합해 판단했다”며 “빙상계 여론과 언론 보도 등을 통해 나오는 시각도 평가에 반영됐다”고 했다.\n",
    "\n",
    "성남시는 지난해 12월 19일 빙상팀 코치를 뽑기 위한 채용 공고를 냈다. 빅토르 안과 베이징 동계올림픽에서 중국 대표팀을 이끈 김선태 전 감독 등 7명이 지원했다. 김 전 감독도 최종 후보에 들지 못한 것으로 전해졌다.\n",
    "\n",
    "빅토르 안은 2006년 토리노 동계올림픽에서 3개의 금메달을 딴 한국 쇼트트랙의 간판이었다. 2011년 소속팀이었던 성남시청이 빙상팀을 해체하자 선수 생활을 이어가기 위해 러시아로 귀화했다. 2014년 소치 동계올림픽에는 러시아 선수로 나서 3관왕에 올랐다. 2018년 평창 동계올림픽 출전이 무산된 이후에는 은퇴를 선언하고 지도자로 변신했다. 2022년 베이징 동계올림픽에서는 중국 대표팀 코치로 활동했다.\n",
    "\n",
    "성남시는 31일 빙상팀 코치 선발 결과를 발표할 예정이다.\"\"\"\n",
    "embeded_content = embedder.encode([arc_content], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c75db23b-46d2-4cab-be41-7cd9ccdaeeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_scores = util.pytorch_cos_sim(embeded_content, embeddings2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b92d30-52ec-4ce1-b9b3-cd4686263628",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ONNX 변환 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0208bf86-45b2-441b-bf80-a36727645da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604031f2-21b9-4475-9277-492c9645abab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b94b2c8-6513-4dc7-807c-336de58efd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 13s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_onnx_list = []\n",
    "for sent in data_fit.iloc[:100,0]:\n",
    "    model_inputs = tokenizer(sent, return_tensors='pt')\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy() for k , v in model_inputs.items()}\n",
    "    try:\n",
    "        embeddings_onnx_list.append(mean_pooling(embedder_onnx.run(None, inputs_onnx), inputs_onnx['attention_mask'])[0][0])\n",
    "    except:\n",
    "        pass\n",
    "embeddings_onnx = torch.stack(embeddings_onnx_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "47479a76-2a77-4aa5-924b-a6b6c0a7e593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "80a7cafc-7c94-4422-a6c3-2f042c003e4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sesac\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_inputs = tokenizer('서울 신문 추미애 구치소 집단 감염 첫 사과 집단 감염 송구 취약 부분 드러나다 빠르다 후속 작업 진행 하다 동부 구치소 관련 확진 총 945 명 서 울 동부 구치소 코로나 19 신종 코로나바이러스 감염증 집단 감염 사태 관련 추미애 법무부 장관 처음 공식 사과 입장 밝히다 동부 구치소 관련 확 진자 발생 지난 11월 말 이후 하다 달이다 만이 추 장관 1일 자신 소셜네트워크서비스 계정 통해 신년인사 전하 동부 구치소 코로나 확산 대해 교정 업무 총괄 있다 법무부 장관 국민 심려 끼치다 드리다 매우 송구 하다 밝히다 법무 행정 취약 부분 드러나다 날 추 장관 코로나 같다 감염병 우리 사회 가장 취약 부분 먼저 무너 뜨다 린다 법무 행정 평소 취약 부분 드러나다 되다 대규모 감염병 사태 아주 치명 수 용소 과밀 그러하다 동부 구치소 지난 12월 25일 전문가 함께 점검 실시 하다 빠르다 집단 감염 원인 주로 3 차 대유행 후 무증상 감염 신입 수용 추정 돼다 말 하다 그렇다 이전 신입 수용 14일 간 격리 후 혼거 수용 하다 절차 준수 하다 하다 그러나 확 진자 증상 없다 걸다 지지 않다 이로 인하다 확산 가능성 여전하다 남아 있다 것 라며 추가 확산 방지 위해 확 진자 비 확 진자 분리 수용 밀도 낮추다 한다는 전문가 권고 받다 전 하다 아우르다 추 장관 동부 구치소 생활 치료 시설 지정 하다 이후 확 진자 수용 하다 시설 재 편하다 빠르다 시일 내 비확 진자 타 교정 기관 송해 분리 하다 계획 라며 또 모범 수형 대한 가석방 확대 형 집행정지 등 동시 진행 하다 빠르다 시 일 내 수용 밀도 낮추다 후속 작업 진행 하다 약속 하다 추 장관 구치소 교도소 달리 구속 또는 형 확정 되다 않다 미결 수 수용 하다 곳 신입 수용 자의 입감 및 출감 빈번 하다 교도소 달리 교정 당국 적정 인원 수용 등 조정 하다 수 있다 곳 아니다 항상 과밀 대한 우려 있다 하다 동부 구치소 감염병 매우 취약 구 조물 추 장관 더군다나 동부 구치소 고층 빌딩 형태 전형 3 밀 밀접 밀집 밀폐 구조 건물 간 간격 촘촘 가리개 설치 공기 흐름 막히다 환기 제대로 안 돼다 감염병 매우 취약 구조 물이 라며 향후 이러하다 부분 대한 개선 반드시 필요하다 것 지적 하다 추 장관 다시 한번 신년인사 전하 저 법무부 장관 임기 마지막 코로나 확산 방지 최선 다 하다 다시 한번 심려 끼치다 드리다 송구 하다 재차 사과 하다 법무부 2 주간 교정 시설 사회 거리 두기 3 단계 법무부 전날 2 주간 교정 시설 사회 거리 두기 3 단계 격상 하다 또 수감 되다 수용 자 불안 커지다 있다 점 고려 모든 교정 시설 직원 및 수용 대상 1 주일 1 이다 3 매 94 마스크 지급 하다 하다 이번 집단 감염 사태 관련 하다 법무부 대처 미흡하다 지적 이어지다 이용구 법무부 차관 당일 브리핑 통해 선제 방역 조치 미흡 이번 같다 사태 발생 하다 음 국민 여러분 송구 하다 말씀 드리다 사과 하다 다만 추 장관 브리핑 참석 하다 않다 추 장관 같다 날 오후 고층 빌딩 형태 인천 구치소 수원구치소 찾다 코로나 19 관련 주요 조치 사항 보고 받다 뒤 직원 및 수용 자의 전 수 검사 지시 하다 선제 방역 조치 중요성 강조 하다 하다 동부 구치소 관련 확 진자 총 945 명 1일 서울시 법무부 따르다 날 오전 0시 기준 동부 구치소 관련 확 진자 총 945 명 격리 추적 검사 과정 수용 131 명의 추가 감염 확인 돼다 교정 당국 따르다 날 오후 5시 기준 동부 구치소 수용 13 명과 직원 1 명 추가 확진 판정 받다 밝히다 확진 수용 13 명 최근 4 차 전 수 조사 결과 나오다 않다 미결 정자 14 명 중 일부 나머지 1 명 음성 판정 나오다 이 따르다 동부 구치소 관련 확 진자 수 수용 915 명 직원 22 명 등 모두 937 명 동부 구치소 지다 감염 지난해 11월 27일 송파구 거주 수능 수험생 최초 확진 판정 받다 이후 이 확 진자 가족 근무 하다 동부 구치소 동료 재소 가족 및 지인 등 급속하다 전파 돼다 하다 달이다 관련 확 진자 945 명 돼다 한편 법무부 공 무직 노동조합 12월 31일 동부 구치소 코로나 19 확 진자 계속 발생 사망자 발생 하다 추 장관 직무 유기 등 혐의 대검찰청 고발 하다 김채현 기자', return_tensors='pt')\n",
    "inputs_onnx = {k: v.cpu().detach().numpy() for k , v in model_inputs.items()}\n",
    "sequence = embedder_onnx.run(None, inputs_onnx)\n",
    "print(sequence)\n",
    "embeddings_onnx = mean_pooling(sequence, inputs_onnx['attention_mask'])[0][0]\n",
    "embeddings_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b390c62f-657b-49bf-80ce-ada3ace76842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "opt = ort.SessionOptions()\n",
    "ort_session = ort.InferenceSession('./model/onnx/ko-sroberta-multitask.onnx', opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2772ab02-6ea7-440e-8938-88318d1f5d1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:5\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sesac\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = '서울 신문 추미애 구치소 집단 감염 첫 사과 집단 감염 송구 취약 부분 드러나다 빠르다 후속 작업 진행 하다 동부 구치소 관련 확진 총 945 명 서 울 동부 구치소 코로나 19 신종 코로나바이러스 감염증 집단 감염 사태 관련 추미애 법무부 장관 처음 공식 사과 입장 밝히다 동부 구치소 관련 확 진자 발생 지난 11월 말 이후 하다 달이다 만이 추 장관 1일 자신 소셜네트워크서비스 계정 통해 신년인사 전하 동부 구치소 코로나 확산 대해 교정 업무 총괄 있다 법무부 장관 국민 심려 끼치다 드리다 매우 송구 하다 밝히다 법무 행정 취약 부분 드러나다 날 추 장관 코로나 같다 감염병 우리 사회 가장 취약 부분 먼저 무너 뜨다 린다 법무 행정 평소 취약 부분 드러나다 되다 대규모 감염병 사태 아주 치명 수 용소 과밀 그러하다 동부 구치소 지난 12월 25일 전문가 함께 점검 실시 하다 빠르다 집단 감염 원인 주로 3 차 대유행 후 무증상 감염 신입 수용 추정 돼다 말 하다 그렇다 이전 신입 수용 14일 간 격리 후 혼거 수용 하다 절차 준수 하다 하다 그러나 확 진자 증상 없다 걸다 지지 않다 이로 인하다 확산 가능성 여전하다 남아 있다 것 라며 추가 확산 방지 위해 확 진자 비 확 진자 분리 수용 밀도 낮추다 한다는 전문가 권고 받다 전 하다 아우르다 추 장관 동부 구치소 생활 치료 시설 지정 하다 이후 확 진자 수용 하다 시설 재 편하다 빠르다 시일 내 비확 진자 타 교정 기관 송해 분리 하다 계획 라며 또 모범 수형 대한 가석방 확대 형 집행정지 등 동시 진행 하다 빠르다 시 일 내 수용 밀도 낮추다 후속 작업 진행 하다 약속 하다 추 장관 구치소 교도소 달리 구속 또는 형 확정 되다 않다 미결 수 수용 하다 곳 신입 수용 자의 입감 및 출감 빈번 하다 교도소 달리 교정 당국 적정 인원 수용 등 조정 하다 수 있다 곳 아니다 항상 과밀 대한 우려 있다 하다 동부 구치소 감염병 매우 취약 구 조물 추 장관 더군다나 동부 구치소 고층 빌딩 형태 전형 3 밀 밀접 밀집 밀폐 구조 건물 간 간격 촘촘 가리개 설치 공기 흐름 막히다 환기 제대로 안 돼다 감염병 매우 취약 구조 물이 라며 향후 이러하다 부분 대한 개선 반드시 필요하다 것 지적 하다 추 장관 다시 한번 신년인사 전하 저 법무부 장관 임기 마지막 코로나 확산 방지 최선 다 하다 다시 한번 심려 끼치다 드리다 송구 하다 재차 사과 하다 법무부 2 주간 교정 시설 사회 거리 두기 3 단계 법무부 전날 2 주간 교정 시설 사회 거리 두기 3 단계 격상 하다 또 수감 되다 수용 자 불안 커지다 있다 점 고려 모든 교정 시설 직원 및 수용 대상 1 주일 1 이다 3 매 94 마스크 지급 하다 하다 이번 집단 감염 사태 관련 하다 법무부 대처 미흡하다 지적 이어지다 이용구 법무부 차관 당일 브리핑 통해 선제 방역 조치 미흡 이번 같다 사태 발생 하다 음 국민 여러분 송구 하다 말씀 드리다 사과 하다 다만 추 장관 브리핑 참석 하다 않다 추 장관 같다 날 오후 고층 빌딩 형태 인천 구치소 수원구치소 찾다 코로나 19 관련 주요 조치 사항 보고 받다 뒤 직원 및 수용 자의 전 수 검사 지시 하다 선제 방역 조치 중요성 강조 하다 하다 동부 구치소 관련 확 진자 총 945 명 1일 서울시 법무부 따르다 날 오전 0시 기준 동부 구치소 관련 확 진자 총 945 명 격리 추적 검사 과정 수용 131 명의 추가 감염 확인 돼다 교정 당국 따르다 날 오후 5시 기준 동부 구치소 수용 13 명과 직원 1 명 추가 확진 판정 받다 밝히다 확진 수용 13 명 최근 4 차 전 수 조사 결과 나오다 않다 미결 정자 14 명 중 일부 나머지 1 명 음성 판정 나오다 이 따르다 동부 구치소 관련 확 진자 수 수용 915 명 직원 22 명 등 모두 937 명 동부 구치소 지다 감염 지난해 11월 27일 송파구 거주 수능 수험생 최초 확진 판정 받다 이후 이 확 진자 가족 근무 하다 동부 구치소 동료 재소 가족 및 지인 등 급속하다 전파 돼다 하다 달이다 관련 확 진자 945 명 돼다 한편 법무부 공 무직 노동조합 12월 31일 동부 구치소 코로나 19 확 진자 계속 발생 사망자 발생 하다 추 장관 직무 유기 등 혐의 대검찰청 고발 하다 김채현 기자'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input = {name : np.atleast_2d(value) for name, value in encoded_input.items()}\n",
    "\n",
    "print(ort_session.run(None, encoded_input)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043ff9b-22ab-42b4-8249-34d862399a4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ONNX + 양자화 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48f39a75-1445-4a81-b716-7767b7eb6d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:5\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sesac\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    198\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Gather node. Name:'/embeddings/position_embeddings/Gather' Status Message: indices element out of data bounds, idx=514 must be within the inclusive range [-514,513]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_onnx_uint8_list = []\n",
    "for sent in data_fit.iloc[:100,0]:\n",
    "    model_inputs = tokenizer(sent, return_tensors='pt')\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy() for k , v in model_inputs.items()}\n",
    "    embeddings_onnx_list.append(mean_pooling(embedder_onnx_uint8.run(None, inputs_onnx), inputs_onnx['attention_mask'])[0][0])\n",
    "embeddings_onnx_uint8 = torch.stack(embeddings_onnx_uint8_list, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

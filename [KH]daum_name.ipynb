{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609ec095-1682-47a0-bb16-f5384a6df249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n190 page 기준 8분 정도\\n휴일 때 대략 100~200 page\\n평일 때 대략 400~500 page \\n\\n한 페이지에 15 기사\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "190 page 기준 8분 정도\n",
    "휴일 때 대략 100~200 page\n",
    "평일 때 대략 400~500 page \n",
    "\n",
    "한 페이지에 15 기사\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d568c3-4f98-474c-9b0e-1bc7cd99e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "start_date = date(2022, 1, 1)\n",
    "end_date = date(2022, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb8e7ed-7439-4b79-9178-e7ccd1005cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.content, 'html.parser', from_encoding='cp949')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62167232-5ae6-4483-a6fb-c81ed629653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(year,month,day):\n",
    "\n",
    "    \n",
    "    date_data = pd.DataFrame()\n",
    "    \n",
    "    year = str(year)\n",
    "    month = str(month).zfill(2)\n",
    "    day = str(day).zfill(2)\n",
    "    date = year+month+day\n",
    "    \n",
    "    \n",
    "    # 마지막 페이지 번호 추출\n",
    "    url = f\"https://news.daum.net/breakingnews/society?page=10&regDate={date}\"\n",
    "    soup = create_soup(url)\n",
    "    last_page = soup.find(\"em\",attrs ={\"class\": \"num_page\"})\n",
    "    last_page_num = int(re.sub(r'[^0-9]', '', last_page.text))\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in notebook.tqdm(range(1,last_page_num+1)):\n",
    "        url = f\"https://news.daum.net/breakingnews/society?page={i}&regDate={date}\"\n",
    "        soup = create_soup(url)\n",
    "\n",
    "        \n",
    "    \n",
    "        # 뉴스 리스트가 포함된 속성 추출\n",
    "        news_list_part = soup.find('ul', attrs={'class':'list_news2 list_allnews'})\n",
    "        \n",
    "        # COLUME : press\n",
    "        press_list = []\n",
    "        press = news_list_part.find_all('span', attrs={'class':'info_news'})\n",
    "        for _span in press:\n",
    "            press_list.append(_span.text.split()[0])\n",
    "        \n",
    "        # 뉴스 링크 리스트 추출\n",
    "        # COLUME : link\n",
    "        link_list = []\n",
    "        news_link_list = news_list_part.find_all('a',attrs={\"class\":\"link_thumb\"})\n",
    "        for news_link in news_link_list:\n",
    "            link_list.append(news_link[\"href\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # COLUME : articleid\n",
    "        articleid = []\n",
    "        for link in link_list:\n",
    "            articleid.append(link.split(\"/\")[-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 뉴스 링크 리스트 추출\n",
    "        # COLUME : link\n",
    "        news_link_list = news_list_part.find_all('a')\n",
    "\n",
    "        # 링크마다 요청\n",
    "        # COLUME : title, content ,journalist\n",
    "        title_list = []\n",
    "        journalist_list = []\n",
    "        content_list = []\n",
    "\n",
    "        for idx, link in enumerate(link_list):\n",
    "            url = link\n",
    "            article_soup = create_soup(url)\n",
    "            article_soup = article_soup.find(\"article\")\n",
    "            \n",
    "            ### title\n",
    "            title = article_soup.find(\"h3\", attrs={'class':\"tit_view\"})\n",
    "            title_list.append(title.text)\n",
    "            \n",
    "            ### journalist\n",
    "            journalist = article_soup.find(\"span\", attrs={'class':\"txt_info\"})\n",
    "            journalist_list.append(journalist.text)\n",
    "            \n",
    "            ### content\n",
    "            content = article_soup.find(\"div\", attrs={'class':\"article_view\"})\n",
    "            \n",
    "            # 이미지 제거 \n",
    "            if content.select_one(\"p.link_figure\") != None:\n",
    "                content.select_one(\"p.link_figure\").decompose()\n",
    "                \n",
    "            \n",
    "            news_contents = content.find_all(\"p\")\n",
    "            news_content= \"\"\n",
    "            for _p in news_contents:\n",
    "                tmp = _p.text\n",
    "                tmp = tmp.replace(\"\\xa0\",\"\")\n",
    "                tmp = tmp.replace(\"\\\\\",\"\")\n",
    "                tmp = tmp.replace(journalist_list[idx],\"\")\n",
    "                if \"@\" in tmp \\\n",
    "                or \"[카카오톡]\" in tmp \\\n",
    "                or \"[전화]\" in tmp \\\n",
    "                or \"[메일]\" in tmp \\\n",
    "                or \"[온라인 제보]\" in tmp \\\n",
    "                or \"[저작권자(c) YTN & YTN plus 무단전재 및 재배포 금지]\" in tmp \\\n",
    "                or \"※ '당신의 제보가 뉴스가 됩니다'\" in tmp :\n",
    "                    continue\n",
    "                        \n",
    "                news_content += tmp\n",
    "\n",
    "                \n",
    "\n",
    "            content_list.append(news_content)\n",
    "            \n",
    "                \n",
    "                \n",
    "        data =  pd.DataFrame(zip(articleid, title_list,journalist_list,press_list,content_list, link_list))\n",
    "            \n",
    "        date_data = pd.concat([date_data, data])\n",
    "    \n",
    "    return date_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "906257eb-f15a-4333-960b-e0b32e594589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [카카오톡] YTN을 검색해 채널 추가 [전화] 02-398-8585 [메일] social@ytn.co.kr [온라인 제보] www.ytn.co.kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bac49695-bb2b-4e90-9af0-c22284e5f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dateutil.rrule import rrule, DAILY\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# for date in notebook.tqdm(list(rrule(DAILY, dtstart=start_date, until=end_date))):\n",
    "#     df = pd.concat([df, get_articles(date.year, date.month, date.day)])\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df = get_articles(date.year, date.month, date.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "17729119-d9ee-46ff-8ac6-d162bf20cec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0c5e701e064b84b7bc2392a37cf036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_articles(2022, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8fdb8394-f64e-4a0b-a876-4ea1ee381a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHTTPSConnectionPool(host='v.daum.net', port=443): Max retries exceeded with url: /v/20220101121016727 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000020C9A0B23A0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))\\n\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "HTTPSConnectionPool(host='v.daum.net', port=443): Max retries exceeded with url: /v/20220101121016727 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000020C9A0B23A0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6152dbed-b65f-4e01-bd28-4cff7df55296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [이데일리  기자] 골판지 제조공장에서 40대 노동자가 끼임 사고로 사망하는 사고가 발생했다. A씨는 머리 등을 크게 다쳐 병원으로 옮겨졌으나 끝내 숨졌다.A씨는 기계 사이에 골판지가 걸려 이를 빼내려고 하다가 사고를 당한 것으로 알려졌다. 경찰은 기계 오작동 여부 등 사고 경위와 작업장 내 안전 수칙 준수 여부 등을 조사할 예정이다.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[101][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7677184b-2ce7-49f7-acd1-62a383f274d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 141 entries, 0 to 12\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       141 non-null    object\n",
      " 1   1       141 non-null    object\n",
      " 2   2       141 non-null    object\n",
      " 3   3       141 non-null    object\n",
      " 4   4       141 non-null    object\n",
      " 5   5       141 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cc3eb-366f-4bfd-afde-29aecdad4dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
